# Machine-Learning-with-Python

Showcase of Machine Learning skills using Python [Achieved 100%]

<p align="center">
  <img width="150" height="150" src="https://github.com/Amertastic/Data-Visualization-with-Python/blob/main/Images/Data_Visual_w_Python.png">
</p>

## Table of Contents

1) Navigating the Git Hub Repository
2) Executive Summary
3) Technologies and Libraries Used
4) Dataset
5) Evaluation

### Navigating the GitHub Repository

- Jupyter Notebooks: The main Jupyter Notebooks can be found in the Notebooks folder.
  - 01 - Simple-Linear-Regression.ipynb
  - 02 - Multiple Linear Regression.ipynb
  - 03 - K-Nearest Neighbours.ipynb
  - 04 - Decision Trees.ipynb
  - 05 - Regression Trees.ipynb
  - 06 - Logistic Regression.ipynb
  - 07 - SVM (Support Vector Machines).ipynb
  - 08 - Multiclass Prediction.ipynb
  - 09 - K-means.ipynb
  - 10 - Credit Card Fraud Detection.ipynb
  - 11 - Taxi Tip Prediction.ipynb
- README.md

### Executive Summary

The "Machine Learning with Python" section of the IBM Data Science Professional Certificate covered various Machine Learning topics, including supervised and unsupervised learning, regression, and classification. The course provided an overview of different algorithms and techniques, such as K Nearest Neighbors, Decision Trees, and Regression Trees, and how to apply them to real-world problems. 

#### 01 - Simple-Linear-Regression.ipynb

Implemented simple linear regression using scikit-learn to model and predict fuel consumption and carbon dioxide emissions. Evaluated the model's accuracy using MSE, MAE, RMSE, and R-squared metrics.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Simple%20Linear%20Regression%201.png" width="100%" height="100%">| 
|:--:| 
| *"Simple Regression Model with a plot of the fit line over the data"* |

#### 02 - Multiple Linear Regression.ipynb

Implemented multiple linear regression using scikit-learn to predict CO2 emissions based on fuel consumption. Explored different features for improved accuracy.

#### 03 - K-Nearest Neighbours.ipynb

 Demonstrates the use of K-Nearest Neighbors algorithm for classification on a customer dataset. The dataset is used to predict customer group membership based on demographic data. The notebook also covers the concept of train-test split for accurate evaluation of the model's performance.

Implemented simple linear regression using scikit-learn to model and predict fuel consumption and carbon dioxide emissions. Evaluated the model's accuracy using MSE, MAE, RMSE, and R-squared metrics.


|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/K-Nearest%20Neighbors%202.png" width="55%" height="55%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/K-Nearest%20Neighbors%201.png" width="150%" height="150%"> | 
|:--:|:--:| 
| *A visualization of the K-Nearest Neighbors algorithm* | *The model accuracy for a different number of neighbors.* |


#### 04 - Decision Trees.ipynb

Demonstrates the use of Decision Trees for classification in healthcare. The dataset contains patient information and drug response, enabling the development of a model to predict suitable medications for future patients. The notebook covers data pre-processing, decision tree setup, modeling, prediction, evaluation, and visualization.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Decision%20Trees%201.png" width="50%" height="50%">| 
|:--:| 
| *Decision Tree Visualization* |

#### 05 - Regression Trees.ipynb

Implemented regression trees using ScikitLearn to predict the median price of houses in Boston based on various features. Evaluated the accuracy of the regression trees.

#### 06 - Logistic Regression.ipynb

This Python notebook demonstrates the use of logistic regression for customer churn prediction in a telecommunications company. The dataset includes customer information such as services, account details, and demographics. The logistic regression model is built using scikit-learn and evaluated using a confusion matrix, which shows the model's performance in predicting customer churn. The results highlight the model's ability to correctly identify customers who leave (churn) and those who stay, providing insights for customer retention strategies.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Logistic%20Regression%201.png" width="100%" height="100%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Logistic%20Regression%202.png" width="100%" height="100%"> | 
|:--:|:--:| 
| *Logistic Regression passes the input through the logistic/sigmoid but then treats the result as a probability* | *Looking at the accuracy of the classifier using a confusion matrix* |

#### 07 - SVM (Support Vector Machines).ipynb

This notebook focuses on using Support Vector Machines (SVM) to classify human cell records as benign or malignant. The SVM algorithm is applied to a dataset containing cell characteristics, and a model is trained and evaluated. The notebook covers data loading, preprocessing, modeling using SVM with the RBF kernel function, and evaluation using metrics like precision, recall, f1-score, and accuracy. The results include a confusion matrix and the f1-score. The Jaccard index is also utilized to measure accuracy.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/SVM%20(Support%20Vector%20Machines)%201.png" width="100%" height="100%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/SVM%20(Support%20Vector%20Machines)%202.png" width="100%" height="100%"> | 
|:--:|:--:| 
| *A line graph of immigration from Haiti* | *A line graph of immigration from from China and India* |

#### 08 - Multiclass Prediction.ipynb

This Python notebook explores the concepts of softmax regression, one-vs-all, and one-vs-one for multi-class classification.


|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Multiclass%20Prediction%201.png" width="100%" height="100%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Multiclass%20Prediction%203.png" width="100%" height="100%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Multiclass%20Prediction%204.png" width="100%" height="100%">| 
|:--:|:--:|:--:| 
| *Bubble Chart*| *Pie Chart*|*Sunbust Chart*|

#### 09 - K-means.ipynb

This Python notebook demonstrates the use of K-Means Clustering for customer segmentation and data analysis. It covers the process of generating random data, setting up K-Means clustering, creating visual plots, and applying K-Means on customer datasets. The notebook also includes preprocessing steps such as dropping categorical variables and normalizing the data. By applying K-Means clustering, insights can be gained from the data and customer segmentation can be performed effectively.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/K-Means%20Clustering%201.png" width="100%" height="100%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/K-Means%20Clustering%202.png" width="100%" height="100%">|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/K-Means%20Clustering%203.png" width="100%" height="100%">| 
|:--:|:--:|:--:| 
| *Bubble Chart*| *Pie Chart*|*Sunbust Chart*|


#### 10 - Credit Card Fraud Detection.ipynb

The Python notebook demonstrates the use of Scikit-Learn and Snap ML libraries to build and evaluate classification models for credit card fraud detection. The dataset used contains information about credit card transactions, with the objective being to predict whether a transaction is fraudulent or legitimate. The models implemented include Decision Tree and Support Vector Machine, and special attention is given to handling the highly unbalanced nature of the dataset.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Credit%20Card%20Fraud%20Detection%201.png" width="35%" height="35%">| 
|:--:| 
| *"Bubble plots of immigration from China and India to visualize any differences with time from 1980 to 2013"* |

#### 11 - Taxi Tip Prediction.ipynb

This Python notebook demonstrates the use of Scikit-Learn and Snap ML libraries to build and evaluate a Decision Tree regression model for predicting taxi tip amounts using a real dataset from the NYC Taxi and Limousine Commission. The dataset is preprocessed, split into training and test sets, and both Scikit-Learn and Snap ML models are trained and evaluated.

|<img src="https://github.com/Amertastic/Machine-Learning-with-Python/blob/main/Images/Taxi%20Tip%20Prediction%201.png" width="55%" height="55%">| 
|:--:| 
| *"Bubble plots of immigration from China and India to visualize any differences with time from 1980 to 2013"* |
